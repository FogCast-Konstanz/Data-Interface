{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570bbd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"meteostat_kn.csv\")\n",
    "df.columns = ['date', 'hour', 'temp', 'dew_point', 'humidity', 'precipitation', 'snow', 'wind_direction', 'wind_speed', 'wind_gust', 'pressure', 'sunshine_minutes', 'code']\n",
    "\n",
    "# Remove rows where the date is newer than the current date\n",
    "current_date = datetime.now().date()\n",
    "df['date'] = pd.to_datetime(df['date'])  # Ensure 'date' column is in datetime format\n",
    "df = df[df['date'] < datetime(current_date.year, current_date.month, current_date.day)]\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4562dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"temp_dew_point_diff\"] = df[\"temp\"] - df[\"dew_point\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871354e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['hour', 'temp', 'dew_point', 'temp_dew_point_diff', 'humidity', 'pressure', 'wind_speed', 'wind_gust']\n",
    "X = df[features]\n",
    "y = df['code']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975c2363",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine X and y into a single DataFrame for easier handling of NaN values\n",
    "data = pd.concat([X, y], axis=1)\n",
    "\n",
    "# Drop rows where any feature or the target is NaN\n",
    "data = data.dropna()\n",
    "\n",
    "# Separate X and y again\n",
    "X = data[features]\n",
    "\n",
    "# Create binary target: 1 if code is 5 (fog) or 6 (freezing fog), else 0\n",
    "y = data['code'].apply(lambda x: 1 if x == 5 or x == 6 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fca4297",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae28d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdc3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 10],\n",
    "    'n_estimators': [50, 100, 200, 500, 1000],\n",
    "    'learning_rate': [0.01, 0.1, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "# Recalculate imbalance ratio\n",
    "ratio = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    scale_pos_weight=ratio,\n",
    "    eval_metric='logloss',\n",
    "    early_stopping_rounds=10\n",
    ")\n",
    "\n",
    "# Set up GridSearchCV\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=xgb_model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1',\n",
    "    cv=5,\n",
    "    verbose=False,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Run grid search\n",
    "grid_search.fit(X_train, y_train, eval_set=[(X_train, y_train),(X_val, y_val)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a245c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "print(\"Best F1 score:\", grid_search.best_score_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "results = best_model.evals_result()\n",
    "\n",
    "epochs = range(len(results['validation_0']['logloss']))\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, results['validation_0']['logloss'], label='Train Loss')\n",
    "plt.plot(epochs, results['validation_1']['logloss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Log Loss')\n",
    "plt.title('Log Loss over Epochs')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940c0786",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[1, 0])  # 1=foggy, 0=not foggy\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Foggy\", \"Not Foggy\"])\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445789c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get indices of false positives (predicted 1, actual 0)\n",
    "false_positives = X_test[(y_pred == 1) & (y_test == 0)].head(10)\n",
    "\n",
    "# Get indices of false negatives (predicted 0, actual 1)\n",
    "false_negatives = X_test[(y_pred == 0) & (y_test == 1)].head(10)\n",
    "\n",
    "print(\"False Positives:\")\n",
    "print(false_positives)\n",
    "\n",
    "print(\"\\nFalse Negatives:\")\n",
    "print(false_negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98143483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "y_scores = best_model.predict_proba(X_test)[:, 1]  # Probabilities for the positive class (foggy)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test, y_scores)\n",
    "ap = average_precision_score(y_test, y_scores)\n",
    "\n",
    "plt.plot(recall, precision, marker='.')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall Curve (AP = {ap:.2f})')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16c43ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "# Compute ROC curve and ROC area\n",
    "fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "roc_auc = roc_auc_score(y_test, y_scores)\n",
    "\n",
    "# Plot the ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (area = {roc_auc:.3f})')\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303e6596",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a32317",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model.save_model(\"../backend/forecast/xgb_foggy.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fogcast",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
